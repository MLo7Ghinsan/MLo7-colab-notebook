{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVYCw2xQeFMKESVK7kJ5gR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLo7Ghinsan/MLo7-colab-notebook/blob/main/so_vits_svc_notebook_mlo7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SO-VITS-SVC NOTEBOOK**\n",
        "\n",
        "You must read and acknowledge the **Terms of Use** in order to understad the guideline.\n",
        "\n",
        "Notebook made and maintained MLo7\n",
        "_Notebook updated on: 3/28/2023_\n",
        "\n",
        "Update log:\n",
        "+ test lauch notebook"
      ],
      "metadata": {
        "id": "58OrAyi-ni6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Terms of Use\n",
        "##### ~~copied from the main repo~~\n",
        "\n",
        "### Please solve the authorization problem of the dataset on your own. You shall be solely responsible for any problems caused by the use of non-authorized datasets for training and all consequences thereof.The repository and its maintainer, svc develop team, have nothing to do with the consequences!\n",
        "\n",
        "1. This project is established for academic exchange purposes only and is intended for communication and learning purposes. It is not intended for production environments.\n",
        "2. Any videos based on sovits that are published on video platforms must clearly indicate in the description that they are used for voice changing and specify the input source of the voice or audio, for example, using videos or audios published by others and separating the vocals as input source for conversion, which must provide clear original video or music links. If your own voice or other synthesized voices from other commercial vocal synthesis software are used as the input source for conversion, you must also explain it in the description.\n",
        "3. You shall be solely responsible for any infringement problems caused by the input source. When using other commercial vocal synthesis software as input source, please ensure that you comply with the terms of use of the software. Note that many vocal synthesis engines clearly state in their terms of use that they cannot be used for input source conversion.\n",
        "4. Continuing to use this project is deemed as agreeing to the relevant provisions stated in this repository README. This repository README has the obligation to persuade, and is not responsible for any subsequent problems that may arise.\n",
        "5. If you distribute this repository's code or publish any results produced by this project publicly (including but not limited to video sharing platforms), please indicate the original author and code source (this repository).\n",
        "6. If you use this project for any other plan, please contact and inform the author of this repository in advance. Thank you very much.\n"
      ],
      "metadata": {
        "id": "2q0l56aFQhAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Section**"
      ],
      "metadata": {
        "id": "tI4lZq3LyYja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "if not os.path.exists(\"/content/play_sound\"):\n",
        "    os.makedirs(\"/content/play_sound\")\n",
        "%cd /content/play_sound\n",
        "!wget -O setup_complete.wav https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/audio/setup_complete.wav\n",
        "\n",
        "#@title #1.0 | SETUP | Install Dependencies and Mount Google Drive\n",
        "\n",
        "%cd /content\n",
        "!rm -rf /content/sample_data\n",
        "!apt-get update\n",
        "!apt-get install aria2\n",
        "!git clone https://github.com/svc-develop-team/so-vits-svc -b 4.0\n",
        "%cd /content/so-vits-svc\n",
        "!pip install --upgrade pip setuptools numba numpy\n",
        "!pip install pyworld praat-parselmouth fairseq tensorboardX numba\n",
        "!aria2c -x 16 -s 16 -j 16 --dir=\"/content/so-vits-svc/hubert\" https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/diff-svc-necessary-checkpoints/checkpoint_best_legacy_500.pt\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"setup complete!\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "\n",
        "chika_dance = '<img src=\"https://cdn.discordapp.com/attachments/816517150175920138/1090112497446563950/icegif-2013.gif\"/>'\n",
        "display(HTML(chika_dance))\n",
        "\n",
        "with open(\"/content/play_sound/setup_complete.wav\", \"rb\") as f:\n",
        "    setup_complete_sound = f.read()\n",
        "Audio(data=setup_complete_sound, autoplay=True)"
      ],
      "metadata": {
        "id": "0YUGpYrXhMck",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #2.0 | Extract data | Resume training from checkpoint\n",
        "%cd /content\n",
        "#@markdown ___\n",
        "#@markdown ###Train from scratch section\n",
        "#@markdown +=========================+\n",
        "#@markdown ####Directory of the zip file that contain all of your recordings that you want to use to train a model\n",
        "train_from_scratch = False #@param {type:\"boolean\"}\n",
        "raw_data_zip_path = \"path-to-the-zip-file-of-your-recordings\"  #@param {type:\"string\"}\n",
        "model_name = \"your-model-name\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ___\n",
        "#@markdown ###Resume training section\n",
        "#@markdown +=======================+\n",
        "#@markdown ####Directory of the folder that contain your latest G_#, and D_# file\n",
        "resume_training_from_checkpoint = False #@param {type:\"boolean\"}\n",
        "#@markdown Directory of the zip file that THIS NOTEBOOK saved, or any zip that is in the same structure\n",
        "preprocessed_data_zip_path = \"/content/drive/MyDrive/so-vits_colab_files/sovits_data_folders.zip\" #@param {type:\"string\"}\n",
        "#@markdown ___\n",
        "\n",
        "\n",
        "if train_from_scratch:\n",
        "  !unzip -od /content/so-vits-svc/dataset_raw/{model_name} {raw_data_zip_path}\n",
        "  clear_output()\n",
        "  print(\"Training option: train a model from scratch\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if resume_training_from_checkpoint:\n",
        "  !unzip -d /content/so-vits-svc {preprocessed_data_zip_path}\n",
        "  clear_output()\n",
        "  print(\"Training option: resume training from latest checkpoint\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "U05CXlAipvJR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #2.1 Start Preprocessing\n",
        "\n",
        "#@markdown Run this cell either way, even if you already preprocessed your data\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "\n",
        "if train_from_scratch:\n",
        "  !python resample.py\n",
        "  clear_output()\n",
        "  !python preprocess_flist_config.py\n",
        "  clear_output()\n",
        "  !python preprocess_hubert_f0.py\n",
        "  clear_output()\n",
        "  sovits_data_dir = \"/content/drive/MyDrive/so-vits_colab_files\"\n",
        "  if not os.path.exists(sovits_data_dir):\n",
        "    os.makedirs(sovits_data_dir)\n",
        "  !zip -r configs dataset\n",
        "  !cp configs/config.json {sovits_data_dir}\n",
        "  clear_output()\n",
        "  print(f\"Necessary data folders zipped and saved to {sovits_data_dir}!\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if resume_training_from_checkpoint:\n",
        "  print(\"You already have the preprocessed files!\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"Check the configs folder and dataset folder inside so-vits-svc to make sure you are good to go before start training\")\n",
        "print(\".... Or you can just ignore this message\")"
      ],
      "metadata": {
        "id": "_ThKTzYs5CfL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#@title #3.0 Start training\n",
        "#@markdown ####Use custom save directory\n",
        "#@markdown This is recommended so you won't lose your progress if colab decides to kick you\n",
        "\n",
        "#@markdown This section also determine if you gonna resume training from latest checkpoint or not\n",
        "\n",
        "#@markdown (Automatically resume if lastest checkpoints are in the folder)\n",
        "use_custom_save_directory = True #@param {type:\"boolean\"}\n",
        "model_save_directory = path-to-custom-model-save-directory #@param {type:\"string\"}g\n",
        "if use_custom_save_directory:\n",
        "  target_string = '  model_dir = os.path.join(\"./logs\", args.model)\\n'\n",
        "  replacement_string = f'  model_dir = os.path.join(\"{model_save_directory}\", args.model)\\n'\n",
        "  with open(\"/content/so-vits-svc/utils.py\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "  target_line_number = None\n",
        "  for i, line in enumerate(lines):\n",
        "    if line == target_string:\n",
        "      target_line_number = i\n",
        "      break\n",
        "  if target_line_number is None:\n",
        "      print(f\"Error: could not find target string '{target_string}' in utils.py\")\n",
        "  else:\n",
        "    lines[target_line_number] = replacement_string\n",
        "    with open(\"/content/so-vits-svc/utils.py\", \"w\") as f:\n",
        "      f.writelines(lines)\n",
        "#@markdown Display tensorboard for the training progress visualization\n",
        "tensorboard = True  #@param {type:\"boolean\"}\n",
        "if tensorboard:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir {model_save_directory}\n",
        "print(f\"Your model will be saved at {model_save_directory}\")\n",
        "!python train.py -c configs/config.json -m 44k"
      ],
      "metadata": {
        "id": "-hEFFTCfZf57",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference Section**\n",
        "upload your audio into \"raw\" folder inside so-vits-svc root directory"
      ],
      "metadata": {
        "id": "oCnbX-OT897k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start inference\n",
        "\n",
        "#@markdown Parameters see [README.MD#inference](https://github.com/svc-develop-team/so-vits-svc#inference)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "wav_filename = \"input_wav.wav\"  #@param {type:\"string\"}\n",
        "model_path = \"path-to-model\"  #@param {type:\"string\"}\n",
        "model_name = \"your-model-name\"  #@param {type:\"string\"}\n",
        "config_path = \"path-to-config\"  #@param {type:\"string\"}\n",
        "trans = \"0\"  #@param {type:\"string\"}\n",
        "cluster_infer_ratio = \"0\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown Generally keep default:\n",
        "\n",
        "slice_db = \"-40\"  #@param {type:\"string\"}\n",
        "wav_format = \"flac\"  #@param {type:\"string\"}\n",
        "wav_output = \"/content/so-vits-svc/results/\" + wav_filename + \"_\" + trans + \"key\" + \"_\" + speaker + \".\" + wav_format\n",
        "\n",
        "!python inference_main.py -n {wav_filename} -m {model_path} -c {config_path} -s {model_name} -t {trans} -cr {cluster_infer_ratio} -sd {slice_db} -wf {wav_format}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown If you dont want to download from here, uncheck this.\n",
        "download_after_inference = False  #@param {type:\"boolean\"}\n",
        "\n",
        "if download_after_inference:\n",
        "  from google.colab import files\n",
        "  files.download(wav_output)"
      ],
      "metadata": {
        "id": "dYnKuKTIj3z1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}