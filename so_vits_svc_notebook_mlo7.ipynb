{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLo7Ghinsan/MLo7-colab-notebook/blob/main/so_vits_svc_notebook_mlo7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SO-VITS-SVC NOTEBOOK**\n",
        "\n",
        "You must read and acknowledge the **Terms of Use** in order to understad the guideline.\n",
        "\n",
        "Notebook made and maintained MLo7.\n",
        "If there's any error or bug on any part then please report to @MLo7#6969 via discord.\n",
        "\n",
        "_Notebook updated on: 3/29/2023_\n",
        "\n",
        "Update log:\n",
        "+ fixed typo in inference"
      ],
      "metadata": {
        "id": "58OrAyi-ni6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Section**"
      ],
      "metadata": {
        "id": "tI4lZq3LyYja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "if not os.path.exists(\"/content/play_sound\"):\n",
        "    os.makedirs(\"/content/play_sound\")\n",
        "%cd /content/play_sound\n",
        "!wget -O setup_complete.wav https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/audio/setup_complete.wav\n",
        "\n",
        "#@title #1.0 | SETUP | Install Dependencies and Mount Google Drive\n",
        "\n",
        "%cd /content\n",
        "!rm -rf /content/sample_data\n",
        "!apt-get update\n",
        "!apt-get install aria2\n",
        "!git clone https://github.com/svc-develop-team/so-vits-svc -b 4.0\n",
        "%cd /content/so-vits-svc\n",
        "!pip install --upgrade pip setuptools numba numpy\n",
        "!pip install pyworld praat-parselmouth fairseq tensorboardX numba\n",
        "!aria2c -x 16 -s 16 -j 16 --dir=\"/content/so-vits-svc/hubert\" https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/diff-svc-necessary-checkpoints/checkpoint_best_legacy_500.pt\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"setup complete!\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "\n",
        "chika_dance = '<img src=\"https://cdn.discordapp.com/attachments/816517150175920138/1090112497446563950/icegif-2013.gif\"/>'\n",
        "display(HTML(chika_dance))\n",
        "\n",
        "with open(\"/content/play_sound/setup_complete.wav\", \"rb\") as f:\n",
        "    setup_complete_sound = f.read()\n",
        "Audio(data=setup_complete_sound, autoplay=True)"
      ],
      "metadata": {
        "id": "0YUGpYrXhMck",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "#@title #2.0 | Extract data | Resume training from checkpoint\n",
        "%cd /content\n",
        "clear_output()\n",
        "#@markdown ___\n",
        "#@markdown ###Train from scratch section\n",
        "#@markdown +=========================+\n",
        "#@markdown ####Directory of the zip file that contain all of your recordings that you want to use to train a model\n",
        "train_from_scratch = False #@param {type:\"boolean\"}\n",
        "raw_data_zip_path = \"path-to-the-zip-file-of-your-recordings\"  #@param {type:\"string\"}\n",
        "model_name = \"your-model-name\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ___\n",
        "#@markdown ###Resume training section\n",
        "#@markdown +=======================+\n",
        "resume_training = False #@param {type:\"boolean\"}\n",
        "#@markdown Directory of the zip file that THIS NOTEBOOK saved, or any zip that is in the same structure\n",
        "preprocessed_data_zip_path = \"path-to-saved-data-zip\" #@param {type:\"string\"}\n",
        "#@markdown ___\n",
        "\n",
        "\n",
        "if train_from_scratch:\n",
        "  if not os.path.exists(f\"/content/so-vits-svc/dataset_raw/{model_name}\"):\n",
        "    os.makedirs(f\"/content/so-vits-svc/dataset_raw/{model_name}\")\n",
        "  with zipfile.ZipFile(raw_data_zip_path, \"r\") as zip_ref:\n",
        "    wav_files = [f for f in zip_ref.namelist() if f.endswith('.wav')]\n",
        "    for file in tqdm(iterable=wav_files, total=len(wav_files), desc=\"Extracting files\", unit=\"files\"):\n",
        "      zip_ref.extract(member=file, path=f\"/content/so-vits-svc/dataset_raw/{model_name}\")\n",
        "  print(\"Training option: train a model from scratch\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if resume_training:\n",
        "  with zipfile.ZipFile(preprocessed_data_zip_path, \"r\") as zip_ref:\n",
        "    for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist()), desc=\"Extracting files\", unit=\"files\"):\n",
        "      zip_ref.extract(member=file, path=\"/content/so-vits-svc\")\n",
        "  print(\" Training option: resume training from preprocessed data\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "U05CXlAipvJR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #2.1 Start Preprocessing\n",
        "\n",
        "#@markdown Run this cell either way, even if you already preprocessed your data\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "\n",
        "if train_from_scratch:\n",
        "  !python resample.py\n",
        "  clear_output()\n",
        "  !python preprocess_flist_config.py\n",
        "  clear_output()\n",
        "  !python preprocess_hubert_f0.py\n",
        "  clear_output()\n",
        "\n",
        "  sovits_data_dir = \"/content/drive/MyDrive/so-vits_colab_files\"\n",
        "\n",
        "  if not os.path.exists(sovits_data_dir):\n",
        "    os.makedirs(sovits_data_dir)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  configs_folder = \"/content/so-vits-svc/configs\"\n",
        "  flists_folder = \"/content/so-vits-svc/filelists\"\n",
        "  dataset_folder = \"/content/so-vits-svc/dataset\"\n",
        "\n",
        "  with zipfile.ZipFile(sovits_data_dir + \"/\" + model_name + \"_preprocessed_data.zip\", \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n",
        "    #config\n",
        "    for folder_name, subfolders, filenames in tqdm(os.walk(configs_folder), desc=\"Zipping configs folder\"):\n",
        "      for filename in filenames:\n",
        "        file_path = os.path.join(folder_name, filename)\n",
        "        zip_file.write(file_path, os.path.relpath(file_path, configs_folder))\n",
        "    \n",
        "    #list files\n",
        "    for folder_name, subfolders, filenames in tqdm(os.walk(flists_folder), desc=\"Zipping filelists folder\"):\n",
        "      for filename in filenames:\n",
        "        file_path = os.path.join(folder_name, filename)\n",
        "        zip_file.write(file_path, os.path.relpath(file_path, flists_folder))\n",
        "    \n",
        "    #dataset\n",
        "    for folder_name, subfolders, filenames in tqdm(os.walk(dataset_folder), desc=\"Zipping dataset folder\"):\n",
        "      for filename in filenames:\n",
        "        file_path = os.path.join(folder_name, filename)\n",
        "        zip_file.write(file_path, os.path.relpath(file_path, dataset_folder))\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(f\"Necessary data folders zipped and saved to {sovits_data_dir}!\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if resume_training:\n",
        "  print(\"You already have the preprocessed files!\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"Check the configs folder and dataset folder inside so-vits-svc to make sure you are good to go before start training\")\n",
        "print(\".... Or you can just ignore this message\")"
      ],
      "metadata": {
        "id": "_ThKTzYs5CfL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#@title #3.0 Start training\n",
        "#@markdown ####Use custom save directory\n",
        "#@markdown This is recommended so you won't lose your progress if colab decides to kick you\n",
        "\n",
        "#@markdown This section also determine if you gonna resume training from latest checkpoint or not\n",
        "\n",
        "#@markdown \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "#@markdown Automatically resume training from a checkpoint when you link model_save_directory to the folder that has \"44k\" folder in it\n",
        "\n",
        "#@markdown [Example]\n",
        "\n",
        "#@markdown training from scratch: /content/drive/MyDrive/so-vits_colab_files/44k\n",
        "\n",
        "#@markdown resume training: /content/drive/MyDrive/so-vits_colab_files\n",
        "\n",
        "#@markdown ---\n",
        "use_custom_save_directory = True\n",
        "model_save_directory = \"path-to-custom-model-save-directory\" #@param {type:\"string\"}\n",
        "\n",
        "if use_custom_save_directory:\n",
        "  search_string = \"model_dir = os.path.join\"\n",
        "  target_line_number = None\n",
        "  with open(\"/content/so-vits-svc/utils.py\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "  for i, line in enumerate(lines):\n",
        "    if search_string in line:\n",
        "      target_line_number = i\n",
        "      break\n",
        "  if target_line_number is None:\n",
        "    print(f\"Error: could not find target string '{search_string}' in utils.py\")\n",
        "  else:\n",
        "    new_line = f'  model_dir = os.path.join(\"{model_save_directory}\", args.model)\\n'\n",
        "    lines[target_line_number] = new_line\n",
        "    with open(\"/content/so-vits-svc/utils.py\", \"w\") as f:\n",
        "      f.writelines(lines)\n",
        "    print(f\"Your model will be saved at {model_save_directory}\")\n",
        "else:\n",
        "  print(\"Your model will be saved inside the logs folder under so-vits-svc root directory\")\n",
        "\n",
        "#@markdown Display tensorboard for the training progress visualization\n",
        "tensorboard = True  #@param {type:\"boolean\"}\n",
        "if tensorboard:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir {model_save_directory}\n",
        "!python train.py -c configs/config.json -m 44k"
      ],
      "metadata": {
        "id": "-hEFFTCfZf57",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference Section**\n",
        "upload your audio into \"raw\" folder inside so-vits-svc root directory"
      ],
      "metadata": {
        "id": "oCnbX-OT897k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start inference\n",
        "\n",
        "#@markdown Parameters see [README.MD#inference](https://github.com/svc-develop-team/so-vits-svc#inference)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "wav_filename = \"input_wav.wav\"  #@param {type:\"string\"}\n",
        "model_path = \"path-to-model\"  #@param {type:\"string\"}\n",
        "model_name = \"your-model-name\"  #@param {type:\"string\"}\n",
        "config_path = \"path-to-config\"  #@param {type:\"string\"}\n",
        "trans = \"0\"  #@param {type:\"string\"}\n",
        "cluster_infer_ratio = \"0\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown Generally keep default:\n",
        "\n",
        "slice_db = \"-40\"  #@param {type:\"string\"}\n",
        "wav_format = \"flac\"  #@param {type:\"string\"}\n",
        "wav_output = \"/content/so-vits-svc/results/\" + wav_filename + \"_\" + trans + \"key\" + \"_\" + model_name + \".\" + wav_format\n",
        "\n",
        "!python inference_main.py -n {wav_filename} -m {model_path} -c {config_path} -s {model_name} -t {trans} -cr {cluster_infer_ratio} -sd {slice_db} -wf {wav_format}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown If you dont want to download from here, uncheck this.\n",
        "download_after_inference = False  #@param {type:\"boolean\"}\n",
        "\n",
        "if download_after_inference:\n",
        "  from google.colab import files\n",
        "  files.download(wav_output)"
      ],
      "metadata": {
        "id": "dYnKuKTIj3z1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}