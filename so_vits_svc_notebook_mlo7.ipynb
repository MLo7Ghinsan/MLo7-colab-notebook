{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLo7Ghinsan/MLo7-colab-notebook/blob/main/so_vits_svc_notebook_mlo7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SO-VITS-SVC NOTEBOOK**\n",
        "\n",
        "You must read and acknowledge the **Terms of Use** in order to understad the guideline.\n",
        "\n",
        "Notebook made and maintained MLo7.\n",
        "If there's any error or bug on any part then please report to @MLo7#6969 via discord.\n",
        "\n",
        "_Notebook updated on: 4/22//2023_\n",
        "\n",
        "Update log:\n",
        "+ added selection error | step 2.0\n",
        "+ added \"Clean model\" section\n",
        "+ switch to 34j/voicepaw's fork | Inference Section\n",
        "+ general inference section update"
      ],
      "metadata": {
        "id": "58OrAyi-ni6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Section**"
      ],
      "metadata": {
        "id": "tI4lZq3LyYja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "if not os.path.exists(\"/content/play_sound\"):\n",
        "    os.makedirs(\"/content/play_sound\")\n",
        "%cd /content/play_sound\n",
        "!wget -O setup_complete.wav https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/audio/setup_complete.wav\n",
        "\n",
        "#@title #1.0 | SETUP | Install Dependencies and Mount Google Drive\n",
        "\n",
        "#@markdown + Sovits 4.0-v2 is experimental (on this notebook). The processes should be the same so there shouldn't be much of a problem.\n",
        "#@markdown + Differences are not listed. but you can refer to [this](https://github.com/svc-develop-team/so-vits-svc/tree/4.0-v2#-40-v2-features) for 4.0-v2\n",
        "\n",
        "#@markdown ### - Select branch -\n",
        "#@markdown | 4.0 | 4.0-v2 |\n",
        "\n",
        "sovits_branch = \"so-vits_4.0\" #@param [\"so-vits_4.0\", \"so-vits_4.0-v2\"]\n",
        "\n",
        "#@markdown ____\n",
        "\n",
        "#@markdown ***Note:*** default that should work out of the box is 4.0, other branches are un-tested in this notebook, but the process should be the same for every version\n",
        "\n",
        "%cd /content\n",
        "!rm -rf /content/sample_data\n",
        "!apt-get update\n",
        "!apt-get install aria2\n",
        "if sovits_branch == \"so-vits_4.0\":\n",
        "  !git clone https://github.com/svc-develop-team/so-vits-svc.git -b 4.0\n",
        "else:\n",
        "  !git clone https://github.com/svc-develop-team/so-vits-svc.git -b 4.0-v2\n",
        "%cd /content/so-vits-svc\n",
        "!pip install --upgrade pip setuptools numba numpy\n",
        "!pip install pyworld praat-parselmouth fairseq tensorboardX numba\n",
        "!aria2c -x 16 -s 16 -j 16 --dir=\"/content/so-vits-svc/hubert\" https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/diff-svc-necessary-checkpoints/checkpoint_best_legacy_500.pt\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"setup complete!\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "\n",
        "chika_dance = '<img src=\"https://cdn.discordapp.com/attachments/816517150175920138/1090112497446563950/icegif-2013.gif\"/>'\n",
        "display(HTML(chika_dance))\n",
        "\n",
        "with open(\"/content/play_sound/setup_complete.wav\", \"rb\") as f:\n",
        "    setup_complete_sound = f.read()\n",
        "Audio(data=setup_complete_sound, autoplay=True)"
      ],
      "metadata": {
        "id": "0YUGpYrXhMck",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "#@title #2.0 | Extract data | Resume training from checkpoint\n",
        "%cd /content\n",
        "clear_output()\n",
        "#@markdown ___\n",
        "#@markdown ###Train from scratch section\n",
        "#@markdown +=========================+\n",
        "#@markdown ####Directory of the zip file that contain all of your recordings that you want to use to train a model\n",
        "train_from_scratch = False #@param {type:\"boolean\"}\n",
        "raw_data_zip_path = \"path-to-the-zip-file-of-your-recordings\"  #@param {type:\"string\"}\n",
        "model_name = \"your-model-name\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ___\n",
        "#@markdown ###Resume training section\n",
        "#@markdown +=======================+\n",
        "resume_training = False #@param {type:\"boolean\"}\n",
        "#@markdown Directory of the zip file that THIS NOTEBOOK saved, or any zip that is in the same structure\n",
        "preprocessed_data_zip_path = \"path-to-saved-data-zip\" #@param {type:\"string\"}\n",
        "#@markdown ___\n",
        "\n",
        "class DeezNutz(Exception):\n",
        "    pass\n",
        "if train_from_scratch and resume_training:\n",
        "# sussy\n",
        "# amogus\n",
        "    raise DeezNutz(\"You can't select both of the options lmao stoopid\")\n",
        "# Hi, this is MLo7\n",
        "# If you are seeing this that means you select both options, you can't do that!\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if not train_from_scratch and not resume_training:\n",
        "# sussy\n",
        "# amogus\n",
        "    raise DeezNutz(\"You need to select something bich\")\n",
        "# Hi, this is MLo7\n",
        "# If you are seeing this that means you didn't select anything!\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if train_from_scratch:\n",
        "  if not os.path.exists(f\"/content/so-vits-svc/dataset_raw/{model_name}\"):\n",
        "    os.makedirs(f\"/content/so-vits-svc/dataset_raw/{model_name}\")\n",
        "  with zipfile.ZipFile(raw_data_zip_path, \"r\") as zip_ref:\n",
        "    wav_files = [f for f in zip_ref.namelist() if f.endswith('.wav')]\n",
        "    for file in tqdm(iterable=wav_files, total=len(wav_files), desc=\"Extracting files\", unit=\"files\"):\n",
        "      zip_ref.extract(member=file, path=f\"/content/so-vits-svc/dataset_raw/{model_name}\")\n",
        "  print(\"Training option: train a model from scratch\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if resume_training:\n",
        "  with zipfile.ZipFile(preprocessed_data_zip_path, \"r\") as zip_ref:\n",
        "    for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist()), desc=\"Extracting files\", unit=\"files\"):\n",
        "      zip_ref.extract(member=file, path=\"/content/so-vits-svc\")\n",
        "  print(\" Training option: resume training from preprocessed data\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "U05CXlAipvJR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #2.1 Start Preprocessing\n",
        "\n",
        "#@markdown Run this cell either way, even if you already preprocessed your data\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "%cd /content/so-vits-svc\n",
        "\n",
        "if train_from_scratch:\n",
        "  !python resample.py\n",
        "  clear_output()\n",
        "  !python preprocess_flist_config.py\n",
        "  clear_output()\n",
        "  !python preprocess_hubert_f0.py\n",
        "  clear_output()\n",
        "\n",
        "  sovits_data_dir = \"/content/drive/MyDrive/so-vits_colab_files\"\n",
        "\n",
        "  if not os.path.exists(sovits_data_dir):\n",
        "    os.makedirs(sovits_data_dir)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  configs_folder = \"configs\"\n",
        "  flists_folder = \"filelists\"\n",
        "  dataset_folder = \"dataset\"\n",
        "\n",
        "  save_data_zip_dir = sovits_data_dir + \"/\" + model_name + \"_preprocessed_data.zip\"\n",
        "\n",
        "  !zip -r {save_data_zip_dir} {configs_folder} {flists_folder} {dataset_folder}\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  print(f\"Necessary data folders zipped and saved to {sovits_data_dir}!\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if resume_training:\n",
        "  print(\"You already have the preprocessed files!\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"Check the configs folder and dataset folder inside so-vits-svc to make sure you are good to go before start training\")\n",
        "print(\".... Or you can just ignore this message\")"
      ],
      "metadata": {
        "id": "_ThKTzYs5CfL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#@title #3.0 Start training\n",
        "#@markdown ####Use custom save directory\n",
        "#@markdown This is recommended so you won't lose your progress if colab decides to kick you\n",
        "\n",
        "#@markdown This section also determine if you gonna resume training from latest checkpoint or not\n",
        "\n",
        "#@markdown \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "#@markdown Automatically resume training from a checkpoint when you link model_save_directory to the folder that has \"44k\" folder in it\n",
        "\n",
        "#@markdown [Example]\n",
        "\n",
        "#@markdown training from scratch: /content/drive/MyDrive/so-vits_colab_files/44k\n",
        "\n",
        "#@markdown resume training: /content/drive/MyDrive/so-vits_colab_files\n",
        "\n",
        "#@markdown ---\n",
        "use_custom_save_directory = True\n",
        "model_save_directory = \"path-to-custom-model-save-directory\" #@param {type:\"string\"}\n",
        "\n",
        "if use_custom_save_directory:\n",
        "  search_string = \"model_dir = os.path.join\"\n",
        "  target_line_number = None\n",
        "  with open(\"/content/so-vits-svc/utils.py\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "  for i, line in enumerate(lines):\n",
        "    if search_string in line:\n",
        "      target_line_number = i\n",
        "      break\n",
        "  if target_line_number is None:\n",
        "    print(f\"Error: could not find target string '{search_string}' in utils.py\")\n",
        "  else:\n",
        "    new_line = f'  model_dir = os.path.join(\"{model_save_directory}\", args.model)\\n'\n",
        "    lines[target_line_number] = new_line\n",
        "    with open(\"/content/so-vits-svc/utils.py\", \"w\") as f:\n",
        "      f.writelines(lines)\n",
        "    print(f\"Your model will be saved at {model_save_directory}\")\n",
        "else:\n",
        "  print(\"Your model will be saved inside the logs folder under so-vits-svc root directory\")\n",
        "\n",
        "#@markdown Display tensorboard for the training progress visualization\n",
        "tensorboard = True  #@param {type:\"boolean\"}\n",
        "if tensorboard:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir {model_save_directory}\n",
        "!python train.py -c configs/config.json -m 44k"
      ],
      "metadata": {
        "id": "-hEFFTCfZf57",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clean model (OPTIONAL) = Decrease the size of your final model\n",
        "\n",
        "#@markdown ####Decrease model's size\n",
        "\n",
        "#@markdown Decrease the size of your final model either for release or just to save space\n",
        "\n",
        "#@markdown The input models will be replaced with the cleaned models. If you wish to keep the (big) old models, please make a copy of those models\n",
        "\n",
        "path_to_G_pth = \"path-to-G.pth\" #@param {type:\"string\"}\n",
        "\n",
        "path_to_D_pth = \"path-to-G.pth\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown ####Reset iteration\n",
        "\n",
        "#@markdown Select this to reset your mode's iteration back to 0, good for when you want to use the model as a pretrained\n",
        "\n",
        "#@markdown In the other words. Steps, and Epochs will be set to 0\n",
        "\n",
        "reset_iteration = False #@param {type:\"boolean\"}\n",
        "\n",
        "import torch\n",
        "\n",
        "clean_G = torch.load(path_to_G_pth)\n",
        "clean_D = torch.load(path_to_D_pth)\n",
        "\n",
        "if reset_iteration == True:\n",
        "  clean_G[\"iteration\"] = 0\n",
        "  clean_D[\"iteration\"] = 0\n",
        "else:\n",
        "  pass\n",
        "\n",
        "clean_G.pop(\"optimizer\", None)\n",
        "clean_G.pop(\"learning_rate\", None)\n",
        "clean_D.pop(\"optimizer\", None)\n",
        "clean_D.pop(\"learning_rate\", None)\n",
        "\n",
        "torch.save(clean_G, path_to_G_pth)\n",
        "torch.save(clean_D, path_to_D_pth)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lHRsDLfL_eXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference Section**\n"
      ],
      "metadata": {
        "id": "oCnbX-OT897k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #1.0 Install dependencies\n",
        "\n",
        "#@markdown The inference part uses 34j/voicepaw's fork so that you can use different pitch estimation methods\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "if not os.path.exists(\"/content/play_sound\"):\n",
        "    os.makedirs(\"/content/play_sound\")\n",
        "%cd /content/play_sound\n",
        "!wget -O setup_complete.wav https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/audio/setup_complete.wav\n",
        "\n",
        "clear_output()\n",
        "\n",
        "%cd /content\n",
        "\n",
        "!python -m pip install -U pip setuptools wheel\n",
        "!pip install -U torch torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -U so-vits-svc-fork\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"setup complete!\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "\n",
        "chika_dance = '<img src=\"https://cdn.discordapp.com/attachments/816517150175920138/1090112497446563950/icegif-2013.gif\"/>'\n",
        "display(HTML(chika_dance))\n",
        "\n",
        "with open(\"/content/play_sound/setup_complete.wav\", \"rb\") as f:\n",
        "    setup_complete_sound = f.read()\n",
        "Audio(data=setup_complete_sound, autoplay=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lB_KBpk9_SPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #2.0 Start inference\n",
        "\n",
        "#@markdown Parameters see [README.MD#inference](https://github.com/svc-develop-team/so-vits-svc#inference)\n",
        "\n",
        "#@markdown\n",
        "\n",
        "input_wav_path = \"path-to-wav\"  #@param {type:\"string\"}\n",
        "model_path = \"path-to-model\"  #@param {type:\"string\"}\n",
        "model_name = \"your-model-name\"  #@param {type:\"string\"}\n",
        "config_path = \"path-to-config\"  #@param {type:\"string\"}\n",
        "f0_method = \"dio\" #@param [\"crepe\", \"crepe-tiny\", \"parselmouth\", \"dio\", \"harvest\"]\n",
        "pitch = 0 #@param {type:\"slider\", min:-16, max:16, step:1}\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown Advanced parameters (keep default if you don't know what they do):\n",
        "\n",
        "threshold_db = \"-40\"  #@param {type:\"string\"}\n",
        "cluster_ratio = 0 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "noise_scale = 0.4 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "pad_seconds = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "chunk_seconds = 0.5 #@param {type:\"slider\", min:0, max:3, step:0.05}\n",
        "output_path = \"path-to_output\"\n",
        "\n",
        "!svc {input_wav_path} -m {model_path} -s {model_name} -c {config_path}  -fm {f0_method} -t {pitch} -db {threshold_db} -cr {cluster_ratio} -n {noise_scale} -p {pad_seconds} -ch {chunk_seconds}\n"
      ],
      "metadata": {
        "id": "dYnKuKTIj3z1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #3.0 Display inferred audio\n",
        "\n",
        "display(Audio(output_path), autoplay=True))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H90w5kFjNstC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
